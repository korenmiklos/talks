Challenges of multidimensional transactional data
-------------------------------------------------

Recent empirical work has used customs transactions data to analyze the patterns of international trade. The availability of such data has opened up to possibility to ask questions beyond the volume of trade and its broad sectoral composition. A typical customs declaration (which serves as the primary unit of observation for most trade statistics) records the exporting and the importing firm, the precise classification of the product being shipped, the precise date of shipments, the mode of transport, and many other logistical details about shipment. This has made it possible, for example, to study the distribution of trade across products, destination markets and firms.

We note that customs data is very similar to transactional data collected by many businesses. Each transaction is characterized by many categorical variables (“dimensions”) and few quantitative variables (“measures” or “facts”). The data can then be effectively represented by a star schema, where each fact is linked to its many dimensions. Such data can be used to study retail purchases, business supply transactions, or international and domestic shipments, for example.

The proliferation of the number of dimensions poses a conceptual as well as a computational challenge to empirical research. The conceptual challenge relates to the sparsity of such data, that is, the high number of potential categories relative to the number of observations. For example, consider a customs dataset recording the exact date of exports, one of 365 days of the year. The potential number of different classifications (firms, products, destination countries and days of the year) can easily mount to 100 trillion categories. It is not only computationally, but also conceptually infeasible to treat these categories as independent observations representing an underyling model of international trade. The computational challenge relates to the need of controlling for unobserved heterogeneity via fixed or random effects. Using standard within transformation is simply not feasible with so many dimension, and neither is the practice of estimating the fixed effects directly.

The talk highlights several new empirical approaches to working with multidimensional data with a large number of dimensions.
